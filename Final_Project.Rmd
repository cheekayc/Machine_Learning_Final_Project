---
title: "Final Project"
author: "Chee Kay Cheong"
output: html_document
---

### Load needed packages
```{r setup, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)

library(tidyverse)
library(finalfit)
library(mice)
library(caret)
library(glmnet)
library(randomForest)
```

# Introduction

Every year, the seasonal flu claims numerous lives across the globe. This highly contagious virus can spread easily and quickly, causing severe health complications, especially in
people with weakened immune systems. Vaccinations are essential to prevent illness, and if enough people receive them, they can create herd immunity, which can help protect the
wider community.

In the spring of 2009, an outbreak of H1N1 influenza, commonly known as "swine flu," spread worldwide, causing a death toll estimated to range from 151,000 to 575,000 in its first
year. A vaccine for the H1N1 flu virus became publicly available in October 2009. Later, in late 2009 and early 2010, the United States conducted the National 2009 H1N1 Flu Survey.
This phone survey collected personal information from participants and asked about their social, economic, and demographic background, views on disease and vaccine efficacy, and
steps taken to reduce the spread of infection. Gaining insights into the relationship between these characteristics and personal vaccination behavior can help inform future public
health initiatives.

### Research Question

The final project will employ a dataset acquired from [Kaggle](https://www.kaggle.com/datasets/arashnic/flu-data) that contains all the survey data gathered. We will use this
dataset **to identify the factors that may influence individuals' likelihood of receiving the H1N1 or seasonal flu vaccinations**.

### Rationale for research question

It is essential for public health to recognize the elements that affect people's probability to receive the H1N1 or seasonal flu shots for a variety of reasons:

1. **Improve disease prevention**
   + Understand what factors influence vaccine uptake can help public health officials target their efforts to increase vaccination rates and prevent outbreaks.
   
2. **Promote health equity**
   + Identifying factors that influence vaccine uptake can help address health disparities and ensure that everyone has access to vaccines. 
   + If certain groups are less likely to get vaccinated due to access barriers or mistrust of vaccines, public health officials can work to address these issues and increase vaccination rates in those populations.
   
3. **Reduce economic impact**
   + The flu can have a significant economic impact due to lost of productivity, healthcare costs, and other related expenses. Increasing vaccination rates and preventing outbreaks can help reduce these economic costs and benefit society as a whole.
   

# Data Preparation

##### Read in and clean dataset.

* Convert all character variables to factor variables.
* Convert the binary outcomes `h1n1_vaccine` and `seasonal_vaccine` from numeric to factor variables.

```{r}
flu_df = read_csv("./H1N1_Flu_Vaccines.csv") %>% 
  janitor::clean_names() %>% 
  select(-respondent_id) %>% 
  mutate(
    age_group = as_factor(age_group),
    education = as_factor(education),
    race = as_factor(race),
    sex = as_factor(sex),
    income_poverty = as_factor(income_poverty),
    marital_status = as_factor(marital_status),
    rent_or_own = as_factor(rent_or_own),
    employment_status = as_factor(employment_status),
    hhs_geo_region = as_factor(hhs_geo_region),
    census_msa = as_factor(census_msa),
    employment_industry = as_factor(employment_industry),
    employment_occupation = as_factor(employment_occupation),
    h1n1_vaccine = as_factor(h1n1_vaccine),
    seasonal_vaccine = as_factor(seasonal_vaccine))
```

##### Examine missing data.
```{r}
missing_plot(flu_df)
```

Based on the plot above, `health_insurance`, `employment_industry`, and `employment_occupation` have the most number of missing values. We could simply remove these three variables, but this may violate the purpose of our research question. Simply removing these variables with missing values may introduce bias to our results.

# Impute missing data

Impute missing data using ***random forest imputation***.
```{r, results = 'hide'}
impute_missing_data = mice(flu_df, meth = "rf", ntree = 5, m = 2, seed = 100)
flu_nomiss = complete(impute_missing_data)
```

Examine the "new" dataset.
```{r}
missing_plot(flu_nomiss)
```

Based on the plot above, there is no more missing values in the new dataset `flu_nomiss`.
Next, we will perform *Elastic Net* to reduce the dimension of the dataset by removing features that are not as important and significant for seasonal and H1N1 vaccines.


# H1N1 vaccines

## Data Partitioning

To understand what variables are responsible for influencing people's probability of receiving the H1N1 vaccines, any variables of seasonal flu will be excluded from this dataset 
before partitioning.
```{r}
set.seed(123)

h1n1 = flu_nomiss %>% 
  select(-seasonal_vaccine, -opinion_seas_vacc_effective, -opinion_seas_risk, -opinion_seas_sick_from_vacc, -doctor_recc_seasonal)

h1n1.train.index = createDataPartition(y = h1n1$h1n1_vaccine, p = 0.7, list = FALSE)
h1n1.train.data = h1n1[h1n1.train.index, ]
h1n1.test.data = h1n1[-h1n1.train.index, ]
```

Examine the number of outcome in the training dataset and determine if we should do "up" or "down" sampling.
```{r}
h1n1.train.data %>% 
  select(h1n1_vaccine) %>% 
  group_by(h1n1_vaccine) %>% 
  count() %>% 
  knitr::kable()
```

We should consider upsampling the observations that received the H1N1 vaccine as there are much fewer of them. However, due to the availability of enough observations to conduct
cross-validation and for the sake of easier computation, we will opt for downsampling instead.

## Feature Selection using Elastic Net

The dataset includes 33 independent variables. To address our research question, it is necessary to conduct dimension reduction and select the most relevant features that have the
greatest impact on our outcome variable.

Fit model into H1N1 training set.
```{r}
set.seed(123)

# Create vectors of lambda and alpha
lambda = 10^seq(-3, 3, length = 100)
alpha = 0.1*seq(1, 10, length = 10)
tune_grid = expand.grid(alpha = alpha, lambda = lambda)

# Set validation method and options
control.settings = trainControl(method = "cv", number = 10, sampling = "down")

# Fit model 
h1n1_model = train(h1n1_vaccine ~ ., data = h1n1.train.data, method = "glmnet", trControl = control.settings, preProcess = c("center", "scale"), tuneGrid = tune_grid)

# Output best values of alpha & lambda
h1n1_model$bestTune
```

##### Examine model coefficients and variable importance.
```{r}
coef(h1n1_model$finalModel, h1n1_model$bestTune$lambda)

varImp(h1n1_model)
```

Based on the model coefficients and variable importance, we identified three variables that are important for people to receive the H1N1 vaccines:                                 
1. `doctor_recc_h1n1` - whether the H1N1 flu vaccine was recommended by doctor.                                                                                                     
2. `opinion_h1n1_risk` - Respondent's opinion about risk of getting sick with H1N1 flu without vaccine.                                                                             
3. `opinion_h1n1_vacc_effective` - Respondent's opinion about H1N1 vaccine effectiveness.


##### Examine full model accuracy

```{r}
confusionMatrix(h1n1_model)
```

The model's average accuracy on the full dataset that includes all variables is 79.59%. Specifically, 11% of the data was correctly classified as having received H1N1 vaccines, while 10.2% of the data classified as not having received the vaccine actually had received it. Additionally, 10.2% of the data that were classified as having received the vaccine had never actually received it. On the other hand, 68.5% of the data were correctly classified as not having received the H1N1 vaccine.


### Select only relevant variables for H1N1 training and testing dataset

```{r}
# Training set
h1n1_select_train = 
  h1n1.train.data %>% 
  select(doctor_recc_h1n1, opinion_h1n1_risk, opinion_h1n1_vacc_effective, h1n1_vaccine)

# Testing set
h1n1_select_test = 
  h1n1.test.data %>% 
  select(doctor_recc_h1n1, opinion_h1n1_risk, opinion_h1n1_vacc_effective, h1n1_vaccine)
```


## Use Random Forests to test variable importance

Once we have selected the features using *elastic net*, we can use *random forests* to test the importance of these selected features. We can fit a random forest model using only the selected features and compare the resulting variable importance measures to those obtained from the full model that includes all available features. If the selected features are indeed important predictors of the outcome, we should see a similar or higher importance score for these features in the reduced model compared to the full model. If the selected features are not important, we would expect their importance scores to be lower in the reduced model.

Fit model into the reduced training set.
```{r}
set.seed(123)

# Try different values of mtry 
mtry.vals.h1n1 = c(ncol(h1n1_select_train)-1, sqrt(ncol(h1n1_select_train)-1), 0.5*ncol(h1n1_select_train)-1)
mtry.grid.h1n1 = expand.grid(.mtry = round(mtry.vals.h1n1))

rf_h1n1 = train(h1n1_vaccine ~ ., data = h1n1_select_train, method = "rf", metric = "Accuracy", tuneGrid = mtry.grid.h1n1, trControl = control.settings, ntree = 100)

rf_h1n1$bestTune
```

Examine variable importance.
```{r}
varImp(rf_h1n1)
```

The variable importance ranking in the reduced model remains the same as the full model. However, the importance of the
`opinion_h1n1_risk` variable has increased, while the importance of `opinion_h1n1_vacc_effective` has reduced to zero. This suggests that a respondent's opinion on the
effectiveness of the H1N1 vaccine may not be a crucial factor in predicting their likelihood of receiving it.                              


## Evaluate the performance of model on the testing set

```{r}
set.seed(123)

pred.rf.test = predict(rf_h1n1, h1n1_select_test)

test.outcome = h1n1_select_test$h1n1_vaccine

confusionMatrix(pred.rf.test, test.outcome, positive = '1')
```

In the reduced dataset, the ***random forests*** model achieves an accuracy of 75.62%, which is roughly 4% lower than the *Elastic Net* model's accuracy on the full
dataset. This decrease in accuracy is expected as we reduced the number of predictors. Despite removing almost 90% of the features, the model's accuracy did not decrease
significantly. This suggests that the selected features are crucial predictors for the model.

Besides, the model also showed a quite balanced sensitivity (0.73) and specificity (0.76).


# Seasonal Flu vaccines

## Data Partitioning

To understand what variables are responsible for influencing people's probability of receiving the seasonal flu vaccines, any variables of H1N1 will be excluded from this dataset
before partitioning.
```{r}
set.seed(123)

seasonal = flu_nomiss %>% 
  select(-h1n1_vaccine, -opinion_h1n1_vacc_effective, -opinion_h1n1_risk, -opinion_h1n1_sick_from_vacc, -doctor_recc_h1n1)

seasonal.train.index = createDataPartition(y = seasonal$seasonal_vaccine, p = 0.7, list = FALSE)
seasonal.train.data = seasonal[seasonal.train.index, ]
seasonal.test.data = seasonal[-seasonal.train.index, ]
```

Examine the number of outcome in the training dataset and determine if we should do "up" or "down" sampling.
```{r}
seasonal.train.data %>% 
  select(seasonal_vaccine) %>% 
  group_by(seasonal_vaccine) %>% 
  count() %>% 
  knitr::kable()
```

The outcome is quite balance, so we might not need any up- or downsampling.

## Feature Selection using Elastic Net

The dataset includes 33 independent variables. To address our research question, it is necessary to conduct dimension reduction and select the most relevant features that have the
greatest impact on our outcome variable.

Fit model into seasonal flu training set.
```{r}
set.seed(123)

# Create vectors of lambda and alpha
lambda = 10^seq(-3, 3, length = 100)
alpha = 0.1*seq(1, 10, length = 10)
tune_grid = expand.grid(alpha = alpha, lambda = lambda)

# Set validation method and options
control.settings = trainControl(method = "cv", number = 10)

# Fit model 
seasonal_model = train(seasonal_vaccine ~ ., data = seasonal.train.data, method = "glmnet", trControl = control.settings, preProcess = c("center", "scale"), tuneGrid = tune_grid)

# Output best values of alpha & lambda
seasonal_model$bestTune
```

##### Examine model coefficients and variable importance.
```{r}
coef(seasonal_model$finalModel, seasonal_model$bestTune$lambda)

varImp(seasonal_model)
```

Based on the model coefficients and variable importance, we decided to select variables that have an overall importance of 20% or higher:                                          
1. `opinion_seas_risk` - Respondent's opinion about risk of getting sick with seasonal flu without vaccine.                                                                         
2. `opinion_seas_vacc_effective` - Respondent's opinion about seasonal flu vaccine effectiveness.                                                                                   
3. `doctor_recc_seasonal` - Whether seasonal flu vaccine was recommended by doctor.                                                                                                 
4. `age_group` - Age group of respondent.                                                                                                                                           
5. `opinion_seas_sick_from_vacc` - Respondent's worry of getting sick from taking seasonal flu vaccine.                                                                             
6. `health_worker` - Whether respondent is a healthcare worker.                                                                                                                     
7. `health_insurance` - Whether respondent has health insurance.


##### Examine full model accuracy

```{r}
confusionMatrix(seasonal_model)
```

The model's average accuracy on the full dataset that includes all variables is 78.32%. Specifically, 35% of the data was correctly classified as having received seasonal flu
vaccines, while 12% of the data classified as not having received the vaccine actually had received it. Additionally, 10% of the data that were classified as having received the vaccine had never actually received it. On the other hand, 43.5% of the data were correctly classified as not having received the H1N1 vaccine.


### Select only relevant variables for seasonal flu training and testing dataset

```{r}
# Training set
seasonal_select_train = 
  seasonal.train.data %>% 
  select(opinion_seas_risk, opinion_seas_vacc_effective, doctor_recc_seasonal, age_group, opinion_seas_sick_from_vacc, health_worker, health_insurance, seasonal_vaccine)

# Testing set
seasonal_select_test = 
  seasonal.test.data %>% 
  select(opinion_seas_risk, opinion_seas_vacc_effective, doctor_recc_seasonal, age_group, opinion_seas_sick_from_vacc, health_worker, health_insurance, seasonal_vaccine)
```


## Use Random Forests to test variable importance

Once we have selected the features using *elastic net*, we can use *random forests* to test the importance of these selected features. We can fit a random forest model using only the selected features and compare the resulting variable importance measures to those obtained from the full model that includes all available features. If the selected features are indeed important predictors of the outcome, we should see a similar or higher importance score for these features in the reduced model compared to the full model. If the selected features are not important, we would expect their importance scores to be lower in the reduced model.

Fit model into the reduced training set.
```{r}
set.seed(123)

# Try different values of mtry 
mtry.vals.seasonal = c(ncol(seasonal_select_train)-1, sqrt(ncol(seasonal_select_train)-1), 0.5*ncol(seasonal_select_train)-1)
mtry.grid.seasonal = expand.grid(.mtry = round(mtry.vals.seasonal))

rf_seasonal = train(
  seasonal_vaccine ~ ., data = seasonal_select_train, method = "rf", metric = "Accuracy", tuneGrid = mtry.grid.seasonal, trControl = control.settings, ntree = 100)

rf_seasonal$bestTune
```

Examine variable importance.
```{r}
varImp(rf_seasonal)
```

The variable importance ranking for the reduced model is very similar to that of the full model. The `opinion_seas_vacc_effective` variable's importance has increased, while the
`doctor_recc_seasonal` variable's importance has decreased slightly. Individuals aged 65 years or older are more likely to receive seasonal flu vaccines than those in other age
groups. Furthermore, the importance of all other selected variables has dropped below 20%, suggesting that they may not significantly influence a person's likelihood of receiving
seasonal flu vaccines.


## Evaluate the performance of model on the testing set

```{r}
set.seed(123)

pred.rf.seasonal = predict(rf_seasonal, seasonal_select_test)

test.outcome.seasonal = seasonal_select_test$seasonal_vaccine

confusionMatrix(pred.rf.seasonal, test.outcome.seasonal, positive = '1')
```

In the reduced dataset, the ***random forests*** model achieves an accuracy of 77.21%, which is only 1% lower than the *Elastic Net* model's accuracy on the full dataset. This
decrease in accuracy is expected as we reduced the number of predictors. Despite removing 77% of the features, the model's accuracy did not decrease significantly. This suggests that the selected features are crucial predictors for the model.

Besides, the model also showed a quite balanced sensitivity (0.74) and specificity (0.80).


# Conclusion

### HIV vaccines 

Through a data-driven approach, we have successfully identified that a doctor's recommendation and an individual's perception of contracting H1N1 flu without a vaccine can
significantly increase the likelihood of receiving the H1N1 vaccine.

### Seasonal Flu vaccines

Using a data-driven approach, we have successfully identified that a doctor's recommendation, an individual's perception of contracting seasonal flu without a vaccine, and their
belief in the vaccine's high efficacy are key factors that can significantly increase the likelihood of receiving the seasonal flu vaccine. Additionally, the data indicates that
individuals in the older age group are more likely to receive seasonal flu vaccines.


## Analytic Limitations

1) Missing data
   + In the present study, it has been observed that three features of the dataset under consideration exhibit a high degree of missingness. While it may be tempting to remove these features from the analysis altogether, it must be noted that such an action may result in introducing bias to the study. The nature of the missing data remains unknown, and it is possible that the missingness is either missing at random (MAR) or not missing at random (NMAR). If indeed the data is MAR or NMAR, removing variables with missing values could potentially bias the results of the analysis.

2) Imputation can introduce bias
   + Imputation, as a technique for handling missing data, carries with it the potential to introduce bias into the results of an analysis if the imputed values do not accurately reflect the true values of the missing data. This risk is particularly salient when the missingness is non-random or associated with unobserved variables. In such cases, imputation may not be able to fully account for the underlying mechanisms driving the missingness, leading to biased results.

## Ethical Consideration

The potential impact of an incorrect output produced by a machine learning model is a significant concern in many research contexts. In the present study, it was noted that the dataset under consideration includes three features with a large number of missing values, and it is unclear whether the missingness is completely at random. The use of imputation methods to handle these missing values raises the possibility that bias may have been introduced into the analysis, which could lead to inaccurate results.

To address this concern, further investigation is required to verify the accuracy of the results obtained using machine learning approaches. Specifically, it may be necessary to incorporate epidemiological knowledge and expertise to supplement the findings obtained from machine learning analyses. By doing so, it may be possible to obtain a more accurate and comprehensive understanding of the relationships between variables and outcomes under consideration.

Overall, it is important to recognize the limitations and potential biases of machine learning methods, particularly when dealing with datasets that include missing values or other sources of potential bias. By taking a cautious and critical approach to the use of machine learning in research, it is possible to obtain more accurate and reliable results that can inform effective decision-making and policy development.

